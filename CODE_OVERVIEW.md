# VisiÃ³n General del CÃ³digo

Este documento proporciona una descripciÃ³n detallada de la implementaciÃ³n del sistema de clasificaciÃ³n de imÃ¡genes mÃ©dicas para la detecciÃ³n temprana de cÃ¡ncer de mama.

## ğŸ—ï¸ Arquitectura General

El proyecto sigue una arquitectura modular con los siguientes componentes principales:

1. **MÃ³dulo de Datos**
   - Carga y preprocesamiento de imÃ¡genes
   - Aumento de datos
   - GeneraciÃ³n de lotes (batching)

2. **Modelos**
   - CNN estÃ¡ndar
   - Mixture of Experts (MoE)

3. **EvaluaciÃ³n**
   - MÃ©tricas de rendimiento
   - Visualizaciones
   - GeneraciÃ³n de reportes

## ğŸ“‚ Estructura de Archivos

```
models/
â”œâ”€â”€ cnn_baseline.py     # ImplementaciÃ³n de la CNN de referencia
â”œâ”€â”€ moe_model.py        # ImplementaciÃ³n del modelo MoE
compare_models.py       # Script para comparar modelos
```

## ğŸ§© Componentes Clave

### 1. cnn_baseline.py

#### Funcionalidades
- Carga del conjunto de datos BreastMNIST
- Preprocesamiento de imÃ¡genes (reescalado, normalizaciÃ³n)
- DefiniciÃ³n de la arquitectura CNN
- Entrenamiento con early stopping
- EvaluaciÃ³n y generaciÃ³n de mÃ©tricas
- Guardado de resultados

#### Arquitectura CNN
```
Input(28, 28, 1)
â”œâ”€ Conv2D(32, 3x3, relu)
â”œâ”€ MaxPooling2D
â”œâ”€ Conv2D(64, 3x3, relu)
â”œâ”€ MaxPooling2D
â”œâ”€ Flatten
â”œâ”€ Dense(64, relu)
â””â”€ Dense(1, sigmoid)
```

### 2. moe_model.py

#### CaracterÃ­sticas
- ImplementaciÃ³n de la arquitectura Mixture of Experts
- MÃºltiples expertos CNN trabajando en paralelo
- Capa de gating para combinar las salidas
- Manejo de desbalance de clases

#### Estructura MoE
```
Input
â”œâ”€ MÃºltiples Expertos (CNNs)
â”œâ”€ Capa de Gating
â””â”€ CombinaciÃ³n Ponderada
```

### 3. compare_models.py

#### Funcionalidades
- Carga de resultados de mÃºltiples ejecuciones
- ComparaciÃ³n de mÃ©tricas de rendimiento
- GeneraciÃ³n de grÃ¡ficos comparativos
- CreaciÃ³n de reportes detallados

## ğŸ”„ Flujo de Datos

1. **Carga de Datos**
   - Se cargan las imÃ¡genes y etiquetas
   - Se aplica preprocesamiento bÃ¡sico

2. **Aumento de Datos** (solo entrenamiento)
   - Rotaciones aleatorias
   - Volteos horizontales/verticales
   - Zoom aleatorio

3. **Entrenamiento**
   - Se entrena el modelo por Ã©pocas
   - Se monitorea el rendimiento en validaciÃ³n
   - Se aplica early stopping

4. **EvaluaciÃ³n**
   - CÃ¡lculo de mÃ©tricas en el conjunto de prueba
   - GeneraciÃ³n de visualizaciones
   - Guardado de resultados

## âš™ï¸ ConfiguraciÃ³n

### HiperparÃ¡metros

| ParÃ¡metro         | Valor por Defecto | DescripciÃ³n                     |
|-------------------|-------------------|---------------------------------|
| batch_size        | 32                | TamaÃ±o del lote                |
| epochs           | 50                | NÃºmero mÃ¡ximo de Ã©pocas        |
| learning_rate    | 1e-3              | Tasa de aprendizaje inicial    |
| patience         | 10                | Paciencia para early stopping   |
| n_experts        | 4                 | NÃºmero de expertos (solo MoE)  |

## ğŸ› ï¸ Uso Avanzado

### Entrenamiento Personalizado
```python
from models.cnn_baseline import train_model

history = train_model(
    train_ds,
    val_ds,
    learning_rate=0.001,
    batch_size=32,
    epochs=100
)
```

### EvaluaciÃ³n de Modelos
```python
from compare_models import compare_models

results = compare_models(
    model_paths=['path/to/model1', 'path/to/model2'],
    test_ds=test_dataset
)
```

## ğŸ“Š MÃ©tricas Implementadas

- PrecisiÃ³n
- Recall
- F1-Score
- AUC-ROC
- Matriz de confusiÃ³n
- Curvas de aprendizaje (pÃ©rdida y precisiÃ³n)

## ğŸ“ Notas de ImplementaciÃ³n

- Se utiliza `TensorFlow` como backend principal
- Los modelos se guardan en formato Keras (`.h5`)
- Las visualizaciones se generan con `matplotlib` y `seaborn`
- El cÃ³digo sigue las mejores prÃ¡cticas de PEP 8

## ğŸš€ Mejoras Futuras

- Implementar bÃºsqueda de hiperparÃ¡metros
- AÃ±adir soporte para otros conjuntos de datos mÃ©dicos
- Implementar tÃ©cnicas avanzadas de regularizaciÃ³n
- AÃ±adir soporte para entrenamiento distribuido
- Calcula pesos de clase para mitigar el desbalance.
- Define una CNN pequeÃ±a con dos capas convolucionales y `Dropout`.
- Entrena el modelo y evalÃºa en el conjunto de prueba mostrando F1 y AUC.

## breast_mnist_moe.ipynb

El notebook repite la exploraciÃ³n de datos, la CNN base y ademÃ¡s implementa una arquitectura **Mixture of Experts** con un *gating network* que combina varios expertos convolucionales. Se prueban configuraciones con 2, 4 y 8 expertos.

Para cada experimento se grafican las curvas de entrenamiento y se reportan F1-score, AUC y la matriz de confusiÃ³n.

